{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo path: /Users/tx44ru/Projects/Kaggle/DisasterTweets\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Repo path:\", repo_path)\n",
    "except:\n",
    "    os.chdir(\"../\")\n",
    "    repo_path = os.getcwd()\n",
    "    print(\"Repo path:\", repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_path = \"data\"\n",
    "use_dir = \"use\"\n",
    "\n",
    "os.chdir(repo_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test.csv', 'train.csv', 'sample_submission.csv']"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text data cleanning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deed are the reason of thi earthquak may a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la rong sask canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all resid ask to shelter in place are be notif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>peopl receiv wildfir evacu order in california</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent thi photo from rubi alaska as sm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rockyfir updat california hwi close in both di...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>flood disast heavi rain caus flash flood of st...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im on top of the hill and i can see a fire in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there an emerg evacu happen now in the build a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>im afraid that the tornado is come to our area</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deed are the reason of thi earthquak may a...   \n",
       "1   4     NaN      NaN               forest fire near la rong sask canada   \n",
       "2   5     NaN      NaN  all resid ask to shelter in place are be notif...   \n",
       "3   6     NaN      NaN    peopl receiv wildfir evacu order in california    \n",
       "4   7     NaN      NaN  just got sent thi photo from rubi alaska as sm...   \n",
       "5   8     NaN      NaN  rockyfir updat california hwi close in both di...   \n",
       "6  10     NaN      NaN  flood disast heavi rain caus flash flood of st...   \n",
       "7  13     NaN      NaN  im on top of the hill and i can see a fire in ...   \n",
       "8  14     NaN      NaN  there an emerg evacu happen now in the build a...   \n",
       "9  15     NaN      NaN     im afraid that the tornado is come to our area   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  \n",
       "5       1  \n",
       "6       1  \n",
       "7       1  \n",
       "8       1  \n",
       "9       1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def txt_cleanning(text):\n",
    "    \"\"\" cleanning:\n",
    "            lowercase\n",
    "            remove numbers\n",
    "            remove punctuation\n",
    "            stem words\n",
    "    \"\"\"\n",
    "    text  = \"\".join([char.lower() for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens]  # remove stopwords and stemming\n",
    "    text = \" \".join([str(elem) for elem in text])\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(lambda x: txt_cleanning(x))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_df, y_df = df[\"text\"], df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (5709,)\n",
      "test: (1904,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\", X_train.shape)\n",
    "print(\"test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE module:\n",
      " <tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7f835cf25bd0>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    print(\"USE module:\\n\", use_module)\n",
    "except:\n",
    "    use_module = hub.load(use_dir)\n",
    "    print(\"USE module:\\n\", use_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_use(text, use_module):\n",
    "    text = [text]\n",
    "    emb = use_module.signatures[\"response_encoder\"](\n",
    "        input=tf.constant(text),\n",
    "        context=tf.constant(text))[\"outputs\"].numpy()\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"This is a test\"\n",
    "get_use(test, use_module).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5709/5709 [03:14<00:00, 29.40it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_use = []\n",
    "\n",
    "for text in tqdm(X_train):\n",
    "    X_train_use.append(get_use(text, use_module).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1904/1904 [01:04<00:00, 29.55it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_use = []\n",
    "\n",
    "for text in tqdm(X_test):\n",
    "    X_test_use.append(get_use(text, use_module).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_use[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_use = []\n",
    "\n",
    "for text in tqdm(X_train):\n",
    "    X_train_use.append(get_use(text, use_module).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the vectorizer method\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer(min_df=3, max_df=0.8, stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=0.8, max_features=None,\n",
       "                min_df=3, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words='english', strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 681,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vec.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = tfidf_vec.transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf_vec.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5709, 3372)"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_input = X_train_use\n",
    "X_test_input = X_test_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train_input, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7478991596638656"
      ]
     },
     "execution_count": 747,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print out the model's accuracy\n",
    "nb.score(X_test_input, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Net classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8318192470>"
      ]
     },
     "execution_count": 777,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, round(input_size / 2))\n",
    "        self.fc2 = nn.Linear(round(input_size / 2), 100)\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "    def predict(self, x):\n",
    "        #Apply sigmoid to output.\n",
    "        pred = self.forward(x)\n",
    "        return pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 930,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deeper NN\n",
    "class SimpleNet_v2(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNet_v2, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.dropout1 = nn.Dropout(p = 0.6)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.dropout2 = nn.Dropout(p = 0.3)\n",
    "        self.fc3 = nn.Linear(512, 32)\n",
    "        self.fc4 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout1(F.relu(self.fc1(x)))\n",
    "        x = self.dropout2(F.relu(self.fc2(x)))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        out = torch.sigmoid(self.fc4(x))\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        #Apply sigmoid to output.\n",
    "        pred = self.forward(x)\n",
    "        return pred.round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_input = X_train_use\n",
    "X_test_input = X_test_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dimension(inp):\n",
    "    if isinstance(inp, list):\n",
    "        return len(inp[0])\n",
    "    if isinstance(inp, np.ndarray):\n",
    "        return inp.shape[1]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_classifier = SimpleNet_v2(get_dimension(X_train_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_model(epoch, model, optimizer, scheduler, name):\n",
    "    train_state = {    \n",
    "    'model' : model,\n",
    "    'state_dict': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict(),\n",
    "    'scheduler': scheduler.state_dict()\n",
    "    }\n",
    "    torch.save(train_state, name)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(simple_classifier.parameters(), lr=0.001, weight_decay = 0.007);\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, 'max', factor = 0.1, patience = 5, verbose=True)\n",
    "\n",
    "# train_loader, test_loader = create_dataloaders(balanced_train_images, balanced_train_labels, pr_test_img, pr_test_labels)\n",
    "best_accuracy = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    30] loss: 0.021\n",
      "Accuracy on EPOCH 1 test images: 58 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.581408\n",
      "[2,    30] loss: 0.019\n",
      "Accuracy on EPOCH 2 test images: 81 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.815126\n",
      "[3,    30] loss: 0.015\n",
      "Accuracy on EPOCH 3 test images: 80 %\n",
      "[4,    30] loss: 0.013\n",
      "Accuracy on EPOCH 4 test images: 81 %\n",
      "[5,    30] loss: 0.013\n",
      "Accuracy on EPOCH 5 test images: 81 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.819328\n",
      "[6,    30] loss: 0.013\n",
      "Accuracy on EPOCH 6 test images: 82 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.820903\n",
      "[7,    30] loss: 0.013\n",
      "Accuracy on EPOCH 7 test images: 81 %\n",
      "[8,    30] loss: 0.013\n",
      "Accuracy on EPOCH 8 test images: 81 %\n",
      "[9,    30] loss: 0.012\n",
      "Accuracy on EPOCH 9 test images: 81 %\n",
      "[10,    30] loss: 0.013\n",
      "Accuracy on EPOCH 10 test images: 82 %\n",
      "[11,    30] loss: 0.013\n",
      "Accuracy on EPOCH 11 test images: 81 %\n",
      "[12,    30] loss: 0.013\n",
      "Accuracy on EPOCH 12 test images: 82 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-04.\n",
      "[13,    30] loss: 0.012\n",
      "Accuracy on EPOCH 13 test images: 82 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.824055\n",
      "[14,    30] loss: 0.012\n",
      "Accuracy on EPOCH 14 test images: 82 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.824580\n",
      "[15,    30] loss: 0.012\n",
      "Accuracy on EPOCH 15 test images: 82 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.825105\n",
      "[16,    30] loss: 0.012\n",
      "Accuracy on EPOCH 16 test images: 82 %\n",
      "[17,    30] loss: 0.012\n",
      "Accuracy on EPOCH 17 test images: 82 %\n",
      "[18,    30] loss: 0.012\n",
      "Accuracy on EPOCH 18 test images: 82 %\n",
      "[19,    30] loss: 0.012\n",
      "Accuracy on EPOCH 19 test images: 82 %\n",
      "[20,    30] loss: 0.012\n",
      "Accuracy on EPOCH 20 test images: 82 %\n",
      "[21,    30] loss: 0.012\n",
      "Accuracy on EPOCH 21 test images: 82 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n",
      "[22,    30] loss: 0.011\n",
      "Accuracy on EPOCH 22 test images: 82 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.825630\n",
      "[23,    30] loss: 0.012\n",
      "Accuracy on EPOCH 23 test images: 82 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.826155\n",
      "[24,    30] loss: 0.012\n",
      "Accuracy on EPOCH 24 test images: 82 %\n",
      "[25,    30] loss: 0.012\n",
      "Accuracy on EPOCH 25 test images: 82 %\n",
      "[26,    30] loss: 0.012\n",
      "Accuracy on EPOCH 26 test images: 82 %\n",
      "[27,    30] loss: 0.011\n",
      "Accuracy on EPOCH 27 test images: 82 %\n",
      "[28,    30] loss: 0.011\n",
      "Accuracy on EPOCH 28 test images: 82 %\n",
      "Saving current model!!!\n",
      "Detailed Accuracy: 0.826681\n",
      "[29,    30] loss: 0.011\n",
      "Accuracy on EPOCH 29 test images: 82 %\n",
      "[30,    30] loss: 0.012\n",
      "Accuracy on EPOCH 30 test images: 82 %\n",
      "[31,    30] loss: 0.012\n",
      "Accuracy on EPOCH 31 test images: 82 %\n",
      "[32,    30] loss: 0.012\n",
      "Accuracy on EPOCH 32 test images: 82 %\n",
      "[33,    30] loss: 0.012\n",
      "Accuracy on EPOCH 33 test images: 82 %\n",
      "[34,    30] loss: 0.011\n",
      "Accuracy on EPOCH 34 test images: 82 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-06.\n",
      "[35,    30] loss: 0.012\n",
      "Accuracy on EPOCH 35 test images: 82 %\n",
      "[36,    30] loss: 0.011\n",
      "Accuracy on EPOCH 36 test images: 82 %\n",
      "[37,    30] loss: 0.011\n",
      "Accuracy on EPOCH 37 test images: 82 %\n",
      "[38,    30] loss: 0.012\n",
      "Accuracy on EPOCH 38 test images: 82 %\n",
      "[39,    30] loss: 0.011\n",
      "Accuracy on EPOCH 39 test images: 82 %\n",
      "[40,    30] loss: 0.012\n",
      "Accuracy on EPOCH 40 test images: 82 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-07.\n",
      "[41,    30] loss: 0.012\n",
      "Accuracy on EPOCH 41 test images: 82 %\n",
      "[42,    30] loss: 0.011\n",
      "Accuracy on EPOCH 42 test images: 82 %\n",
      "[43,    30] loss: 0.012\n",
      "Accuracy on EPOCH 43 test images: 82 %\n",
      "[44,    30] loss: 0.012\n",
      "Accuracy on EPOCH 44 test images: 82 %\n",
      "[45,    30] loss: 0.012\n",
      "Accuracy on EPOCH 45 test images: 82 %\n",
      "[46,    30] loss: 0.011\n",
      "Accuracy on EPOCH 46 test images: 82 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-08.\n",
      "[47,    30] loss: 0.012\n",
      "Accuracy on EPOCH 47 test images: 82 %\n",
      "[48,    30] loss: 0.012\n",
      "Accuracy on EPOCH 48 test images: 82 %\n",
      "STOPPED EARLY!!\n",
      "Finished Training\n",
      "CPU times: user 9min 31s, sys: 5.45 s, total: 9min 37s\n",
      "Wall time: 38.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "EARLY_STOP = 0\n",
    "EPOCH = 50\n",
    "batchsize = 128\n",
    "model_name = 'SimpleNet_use_3layers.pt'\n",
    "\n",
    "for epoch in range(EPOCH):  # loop over the dataset multiple times\n",
    "    if EARLY_STOP >= 21:\n",
    "        print(\"STOPPED EARLY!!\")\n",
    "        break\n",
    "    simple_classifier.train()\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(y_train), batchsize):\n",
    "        \n",
    "        inputs = torch.tensor(X_train_input[i:i+batchsize]).float()\n",
    "        lbs = torch.tensor(y_train[i:i+batchsize].values).float()\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = simple_classifier(inputs)\n",
    "        loss = criterion(outputs, lbs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i/batchsize) % 30 == 29:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, (i/batchsize) + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    simple_classifier.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for j in range(0, len(y_test), batchsize):\n",
    "        labels = torch.tensor(y_test[j:j+batchsize].values)\n",
    "        outputs = simple_classifier.predict(torch.tensor(X_test_input[j:j+batchsize]).float())\n",
    "        total += labels.shape[0]\n",
    "        correct += outputs.squeeze().eq(labels).sum().item()\n",
    "    cur_accuracy = correct / total\n",
    "    print('Accuracy on EPOCH %d test images: %d %%' % (epoch+1, 100 * cur_accuracy))   \n",
    "    lr_scheduler.step(cur_accuracy)\n",
    "    if cur_accuracy > best_accuracy:\n",
    "            best_accuracy = cur_accuracy\n",
    "            print(\"Saving current model!!!\")\n",
    "            print(\"Detailed Accuracy: %f\" %(best_accuracy))\n",
    "            save_model(epoch, simple_classifier, optimizer, lr_scheduler, model_name)\n",
    "            EARLY_STOP = 0\n",
    "    EARLY_STOP += 1\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 937,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# give best_classifier the class of the model you want to load\n",
    "best_classifier = simple_classifier\n",
    "\n",
    "best_classifier.load_state_dict(torch.load('SimpleNet_use_3layers.pt')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - Test:\n",
      "0.8266806722689075\n"
     ]
    }
   ],
   "source": [
    "best_classifier.eval()\n",
    "preds = best_classifier.predict(torch.tensor(X_test_input).float()).detach().numpy()\n",
    "print(\"Accuracy - Test:\")\n",
    "print((preds.squeeze() == y_test).sum().item() / y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 939,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - Train:\n",
      "0.8421790155894202\n"
     ]
    }
   ],
   "source": [
    "best_classifier.eval()\n",
    "preds = best_classifier.predict(torch.tensor(X_train_input).float()).detach().numpy()\n",
    "print(\"Accuracy - Train:\")\n",
    "print((preds.squeeze() == y_train).sum().item() / y_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is a forest fire at spot pond, geese are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
       "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
       "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
       "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
      ]
     },
     "execution_count": 940,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "# df_test[\"text\"] = df_test[\"text\"].apply(lambda x: txt_cleanning(x))\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_X, submit_y = df_test[\"text\"], df_test[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 942,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_X_tfidf = tfidf_vec.transform(submit_X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 943,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3263/3263 [01:52<00:00, 29.04it/s]\n"
     ]
    }
   ],
   "source": [
    "submit_X_use = []\n",
    "\n",
    "for text in tqdm(submit_X):\n",
    "    submit_X_use.append(get_use(text, use_module).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 944,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_X_inputs = submit_X_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 945,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_preds = best_classifier.predict(torch.tensor(submit_X_inputs).float()).detach().numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_submit_df = pd.DataFrame(submit_preds, columns=[\"target\"])\n",
    "\n",
    "to_submit_df = pd.concat((df_test[\"id\"], to_submit_df), axis = 1)\n",
    "\n",
    "to_submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 22.2k/22.2k [00:02<00:00, 7.95kB/s]\n",
      "403 - Your team has used its submission allowance (5 of 5). This resets at midnight UTC (3.2 hours from now).\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions submit -c nlp-getting-started  -f submission.csv -m \"Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
